{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ+DB2TTscBCt8uDNITMzy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorshedulHoque/Web-Scrapping/blob/main/Web_scrapping_with_Beautiful_Soap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paragraph**"
      ],
      "metadata": {
        "id": "O3Az6XjIGz0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import**"
      ],
      "metadata": {
        "id": "k9b9oELeETyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iPuvokDQEEUj"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup \n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Send request to the website and get response**"
      ],
      "metadata": {
        "id": "5nG5tPrtEdLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "website = 'https://subslikescript.com/movie/Titanic-120338'\n",
        "result = requests.get(website)     \n",
        "content = result.text\n",
        "soup = BeautifulSoup(content, 'lxml')"
      ],
      "metadata": {
        "id": "i0vd6iqmEWom"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select the specific section with tag**"
      ],
      "metadata": {
        "id": "I4eHvxIjF0Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script = soup.find('div', class_= 'full-script')\n",
        "transcript = script.get_text(strip=True, separator=' ')"
      ],
      "metadata": {
        "id": "bB0eUc1dEWrq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the scrapped file**"
      ],
      "metadata": {
        "id": "lFenHw7eGEw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('titanic.txt', 'w', encoding=\"utf-8\") as file:\n",
        "    file.write(transcript)"
      ],
      "metadata": {
        "id": "3cb3Vtw7EWuj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scrapping multiple page**"
      ],
      "metadata": {
        "id": "L0XybnYPG93C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'https://subslikescript.com'\n",
        "website = f\"{root}/movies\"\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "soup = BeautifulSoup(content, 'lxml')"
      ],
      "metadata": {
        "id": "7xKQloW9G8rc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_links = []\n",
        "box1 = soup.find('ul', class_ = 'scripts-list')\n",
        "links = box1.find_all('a', href =True)\n",
        "for link in links:\n",
        "    movie_links.append(link['href'])\n",
        "    \n",
        "print(movie_links)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaGSDBKYG9Wz",
        "outputId": "1cc4bb86-a6f5-4417-ab98-ac18de68dac1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['movie/Blind_Detective-2332707', 'movie/Killer_Workout-91339', 'movie/Budapest_Noir-5161018', 'movie/Firefly-3582840', 'movie/Warriors_of_the_Rainbow_Seediq_Bale_II-4164468', 'movie/Sex_Appeal-91927', 'movie/Lonesome-15258032', 'movie/Corri_uomo_corri-62825', 'movie/Faraway-18747542', 'movie/The_Treasure_of_Swamp_Castle-137226', 'movie/Fantastic_Girls-4028826', 'movie/Meet_Me_in_the_Bathroom-16378298', 'movie/Shot-301171', 'movie/LasseMajas_detektivbyr_-_Stella_Nostra-4397382', 'movie/In_Real_Life-1087453', 'movie/The_Earth_Dies_Screaming-58050', 'movie/The_Mystery_of_Anthrax_Island-19863080', 'movie/Men_of_Plastic-23157348', 'movie/Ela_Veezha_Poonchira-15516546', 'movie/Married_by_Mistake-21403538', 'movie/The_Mask_of_the_Red_Death_Part_2-21443400', 'movie/A_spol_macskak-67816', 'movie/0815_-_In_der_Heimat-47789', 'movie/Level_Five-116866', 'movie/Mothman-1514425', 'movie/My_Favorite_Christmas_Tree-19895682', 'movie/Mistletoe_Match-18559372', 'movie/Adieu_Paris-13492256', 'movie/Smyrna-11935566', 'movie/Chuecatown-856776']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for link in movie_links:\n",
        "    website = f'{root}/{link}'\n",
        "    result = requests.get(website)\n",
        "    # print(website)\n",
        "    content = result.text\n",
        "    soup = BeautifulSoup(content,'lxml')\n",
        "\n",
        "    box = soup.find('article', class_='main-article')\n",
        "\n",
        "    title = box.find('h1').get_text()\n",
        "    print(title)\n",
        "    transcript = box.find('div', class_='full-script').get_text(strip=True, separator=' ')\n",
        "\n",
        "    try:\n",
        "      with open(f'{title}.txt','w', encoding=\"utf-8\") as file:\n",
        "        file.write(transcript)\n",
        "    except:\n",
        "      print(\"Error in file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdzY9km5G9Z7",
        "outputId": "67a787ad-d17c-4319-95ae-918e7a088a80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blind Detective (2013) - full transcript\n",
            "Killer Workout (1987) - full transcript\n",
            "Budapest Noir (2017) - full transcript\n",
            "Firefly (2013) - full transcript\n",
            "Warriors of the Rainbow: Seediq Bale II (2011) - full transcript\n",
            "Sex Appeal (1986) - full transcript\n",
            "Lonesome (2022) - full transcript\n",
            "Corri uomo corri (1968) - full transcript\n",
            "Faraway (2023) - full transcript\n",
            "The Treasure of Swamp Castle (1985) - full transcript\n",
            "Fantastic Girls (2015) - full transcript\n",
            "Meet Me in the Bathroom (2022) - full transcript\n",
            "Shot (1973) - full transcript\n",
            "LasseMajas detektivbyrå - Stella Nostra (2015) - full transcript\n",
            "In Real Life (2008) - full transcript\n",
            "The Earth Dies Screaming (1964) - full transcript\n",
            "The Mystery of Anthrax Island (2022) - full transcript\n",
            "Men of Plastic (2022) - full transcript\n",
            "Ela Veezha Poonchira (2022) - full transcript\n",
            "Married by Mistake (2023) - full transcript\n",
            "The Mask of the Red Death, Part 2 (2023) - full transcript\n",
            "A sípoló macskakö (1972) - full transcript\n",
            "08/15 - In der Heimat (1955) - full transcript\n",
            "Error in file\n",
            "Level Five (1997) - full transcript\n",
            "Mothman (2010) - full transcript\n",
            "My Favorite Christmas Tree (2022) - full transcript\n",
            "Mistletoe Match (2022) - full transcript\n",
            "Adieu Paris (2021) - full transcript\n",
            "Smyrna (2021) - full transcript\n",
            "Chuecatown (2007) - full transcript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plagination**"
      ],
      "metadata": {
        "id": "4qW8ESBJXlyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get The HTML\n",
        "root = 'https://subslikescript.com'  # Homepage of the website\n",
        "website = f'{root}/movies_letter-A'  # Concatenating the homepage with the movies \"letter-A\" section. You can choose any section (e.g., letter-A, letter-B, ...)\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "soup = BeautifulSoup(content, 'lxml')"
      ],
      "metadata": {
        "id": "qIrY0IYoXkrT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Locate the box that contains the pagination bar\n",
        "pagination = soup.find('ul', class_='pagination')\n",
        "pages = pagination.find_all('li', class_='page-item')\n",
        "last_page = pages[-2].text  # this is the number of pages that the website has inside the movies \"letter A\" section"
      ],
      "metadata": {
        "id": "WapQbFKsXk2B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all tbe pages and sending a request to each link\n",
        "for page in range(1, int(last_page)+1)[:2]:     #for 2 pages\n",
        "    result = requests.get(f'{website}?page={page}')  # structure --> https://subslikescript.com/movies_letter-A?page=2\n",
        "    content = result.text\n",
        "    soup = BeautifulSoup(content, 'lxml')\n",
        "\n",
        "    # Locate the box that contains a list of movies\n",
        "    box = soup.find('article', class_='main-article')\n",
        "\n",
        "    # Store each link in \"links\" list (href doesn't consider root aka \"homepage\", so we have to concatenate it later)\n",
        "    links = []\n",
        "    for link in box.find_all('a', href=True):  # find_all returns a list\n",
        "        links.append(link['href'])\n",
        "\n",
        "    for link in links:\n",
        "        try:  # \"try the code below. if something goes wrong, go to the \"except\" block\"\n",
        "            result = requests.get(f'{root}/{link}')  # structure --> https://subslikescript.com/movie/X-Men_2-290334\n",
        "            content = result.text\n",
        "            soup = BeautifulSoup(content, 'lxml')\n",
        "\n",
        "            # Locate the box that contains title and transcript\n",
        "            box = soup.find('article', class_='main-article')\n",
        "            # Locate title and transcript\n",
        "            title = box.find('h1').get_text()\n",
        "            transcript = box.find('div', class_='full-script').get_text(strip=True, separator=' ')\n",
        "\n",
        "            # Exporting data in a text file with the \"title\" name\n",
        "            with open(f'{title}.txt', 'w') as file:\n",
        "                file.write(transcript)\n",
        "        except:\n",
        "            print('------ Link not working -------')\n",
        "            print(link)"
      ],
      "metadata": {
        "id": "oqUe7i_yXk5R"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}